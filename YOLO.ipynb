{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWMcISyGpA1m",
        "outputId": "a1882f25-61e7-4a34-c908-fd61d9c8fe9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Retrieving folder contents\n",
            "Processing file 1tytlWWD1IqtyH3UY1cNDe5y00QJwuGh7 coco2017_subset.zip\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1tytlWWD1IqtyH3UY1cNDe5y00QJwuGh7\n",
            "From (redirected): https://drive.google.com/uc?id=1tytlWWD1IqtyH3UY1cNDe5y00QJwuGh7&confirm=t&uuid=9ad747f6-31c1-46bf-b0cf-5ec88a85a4fb\n",
            "To: /content/shared_folder/coco2017_subset.zip\n",
            "100% 6.71G/6.71G [02:14<00:00, 50.0MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!gdown --folder --id 1B19RWODijlUlXEdvLKxjcmlg-BiJcbWE -O /content/shared_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7SDOoFzqx34",
        "outputId": "36b487b2-2c1a-49f9-9aa6-67ba6bc35133"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['coco2017_subset.zip']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir(\"/content/shared_folder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGVPFHqXq1P7",
        "outputId": "9251c789-df50-473e-9b4d-c8c424b948c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/shared_folder/coco2017_subset.zip\n",
            "replace /content/extracted_files/coco2017_subset/annotation_subset/captions_train2017_subset.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/shared_folder/coco2017_subset.zip -d /content/extracted_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZMO13CvCrcFy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7LORgfNiruo7"
      },
      "outputs": [],
      "source": [
        "# Path to your COCO annotation file (change this to your subset JSON file)\n",
        "ANNOTATION_FILE = '/content/extracted_files/coco2017_subset/annotation_subset/instances_train2017_subset.json'\n",
        "# Folder where the corresponding images are stored\n",
        "IMAGE_FOLDER = '/content/extracted_files/coco2017_subset/train2017'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbdZkOoIr3YN",
        "outputId": "47db3c81-dc6c-4a26-a858-6b95f96a7e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=4.10s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "# Initialize COCO API for instance annotations\n",
        "coco = COCO(ANNOTATION_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCJRPP4qRjDn",
        "outputId": "2bea8b69-77a6-4056-e8bb-365a8e5e3f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/extracted_files/coco2017_subset\n"
          ]
        }
      ],
      "source": [
        "%cd /content/extracted_files/coco2017_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYvSddL7Rp8M",
        "outputId": "f5b4d063-0905-4949-ee14-fb34fbe00679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
            "Total Classes: 80\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load COCO annotations\n",
        "with open('/content/extracted_files/coco2017_subset/annotation_subset/instances_train2017_subset.json') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Extract class names\n",
        "class_names = [category['name'] for category in coco_data['categories']]\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Total Classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziZqQUVgAmxB",
        "outputId": "9c9b7df5-6417-4a75-ae1f-e5961706e3ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset.yaml created successfully!\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "# .yaml configuration\n",
        "data = {\n",
        "    'path': '/content/extracted_files/coco2017_subset/',    # Root directory\n",
        "    'train': '/content/extracted_files/coco2017_subset/train2017/',            # Path to preprocessed train images relative to root\n",
        "    'val': '/content/extracted_files/coco2017_subset/val2017/',                # Path to val images relative to root\n",
        "    'test': '/content/extracted_files/coco2017_subset/test2017/',\n",
        "     'nc': num_classes,  # Number of classes (from COCO annotations)\n",
        "    'names': class_names  # Class names (from COCO annotations)           # Path to test images relative to root\n",
        "\n",
        "}\n",
        "\n",
        "# Save the .yaml file in cocodataset folder\n",
        "with open('/content/extracted_files/coco2017_subset/dataset.yaml', 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "print(\"dataset.yaml created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M0-ZvONSF2L",
        "outputId": "e5ad5852-458b-4161-f5c5-22d2236733f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "names:\n",
            "- person\n",
            "- bicycle\n",
            "- car\n",
            "- motorcycle\n",
            "- airplane\n",
            "- bus\n",
            "- train\n",
            "- truck\n",
            "- boat\n",
            "- traffic light\n",
            "- fire hydrant\n",
            "- stop sign\n",
            "- parking meter\n",
            "- bench\n",
            "- bird\n",
            "- cat\n",
            "- dog\n",
            "- horse\n",
            "- sheep\n",
            "- cow\n",
            "- elephant\n",
            "- bear\n",
            "- zebra\n",
            "- giraffe\n",
            "- backpack\n",
            "- umbrella\n",
            "- handbag\n",
            "- tie\n",
            "- suitcase\n",
            "- frisbee\n",
            "- skis\n",
            "- snowboard\n",
            "- sports ball\n",
            "- kite\n",
            "- baseball bat\n",
            "- baseball glove\n",
            "- skateboard\n",
            "- surfboard\n",
            "- tennis racket\n",
            "- bottle\n",
            "- wine glass\n",
            "- cup\n",
            "- fork\n",
            "- knife\n",
            "- spoon\n",
            "- bowl\n",
            "- banana\n",
            "- apple\n",
            "- sandwich\n",
            "- orange\n",
            "- broccoli\n",
            "- carrot\n",
            "- hot dog\n",
            "- pizza\n",
            "- donut\n",
            "- cake\n",
            "- chair\n",
            "- couch\n",
            "- potted plant\n",
            "- bed\n",
            "- dining table\n",
            "- toilet\n",
            "- tv\n",
            "- laptop\n",
            "- mouse\n",
            "- remote\n",
            "- keyboard\n",
            "- cell phone\n",
            "- microwave\n",
            "- oven\n",
            "- toaster\n",
            "- sink\n",
            "- refrigerator\n",
            "- book\n",
            "- clock\n",
            "- vase\n",
            "- scissors\n",
            "- teddy bear\n",
            "- hair drier\n",
            "- toothbrush\n",
            "nc: 80\n",
            "path: /content/extracted_files/coco2017_subset/\n",
            "test: /content/extracted_files/coco2017_subset/test2017/\n",
            "train: /content/extracted_files/coco2017_subset/train2017/\n",
            "val: /content/extracted_files/coco2017_subset/val2017/\n"
          ]
        }
      ],
      "source": [
        "!cat /content/extracted_files/coco2017_subset/dataset.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LtU-aUfP5Fjk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "0ZJYKgF6-css"
      },
      "outputs": [],
      "source": [
        "# Path to COCO annotation file and output folder for YOLO labels\n",
        "coco_ann_file = \"/content/extracted_files/coco2017_subset/annotation_subset/instances_val2017_subset.json\"\n",
        "output_dir =\"/content/extracted_files/coco2017_subset/val2017\"\n",
        "#Similarly for the train images\n",
        "# defining paths\n",
        "coco_ann_file = '/content/extracted_files/coco2017_subset/annotation_subset/instances_train2017_subset.json'\n",
        "output_dir = '/content/extracted_files/coco2017_subset/train2017'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HTOPzQuh--sM"
      },
      "outputs": [],
      "source": [
        "# Load COCO annotations\n",
        "with open(coco_ann_file, 'r') as f:\n",
        "    coco_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NT0BFjpM_Bap"
      },
      "outputs": [],
      "source": [
        "# Create mapping: COCO category id -> new id (0-based contiguous indices)\n",
        "# For example, if valid categories are 1, 2, 3, 5, 6, ... then you might have:\n",
        "coco_categories = sorted([cat['id'] for cat in coco_data['categories']])\n",
        "id_mapping = {orig_id: new_id for new_id, orig_id in enumerate(coco_categories)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "SDP3r2ep_FYH"
      },
      "outputs": [],
      "source": [
        "# Build a mapping from image_id to image info\n",
        "img_info = {img['id']: img for img in coco_data['images']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "AzTfgMhL_OED"
      },
      "outputs": [],
      "source": [
        "# Process annotations per image\n",
        "annotations_by_image = {}\n",
        "for ann in coco_data['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    img = img_info[img_id]\n",
        "    img_width, img_height = img['width'], img['height']\n",
        "\n",
        "    x, y, w, h = ann['bbox']\n",
        "    # Convert COCO bbox [x, y, w, h] to YOLO format [x_center, y_center, width, height] normalized\n",
        "    x_center = (x + w / 2) / img_width\n",
        "    y_center = (y + h / 2) / img_height\n",
        "    norm_w = w / img_width\n",
        "    norm_h = h / img_height\n",
        "\n",
        "    # Remap the category id\n",
        "    orig_cat = ann['category_id']\n",
        "    if orig_cat not in id_mapping:\n",
        "        continue  # skip if the category is not in the mapping\n",
        "    new_cat = id_mapping[orig_cat]\n",
        "\n",
        "    if img_id not in annotations_by_image:\n",
        "        annotations_by_image[img_id] = []\n",
        "    annotations_by_image[img_id].append(f\"{new_cat} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "j-8D8eSk_Qf-"
      },
      "outputs": [],
      "source": [
        "# Write YOLO label files for each image\n",
        "for img_id, ann_list in annotations_by_image.items():\n",
        "    file_name = img_info[img_id]['file_name']\n",
        "    base_name = os.path.splitext(file_name)[0]\n",
        "    # Save the label file in the same directory as your images, or wherever you prefer\n",
        "    out_file = os.path.join(output_dir, base_name + '.txt')\n",
        "    with open(out_file, 'w') as f:\n",
        "        for line in ann_list:\n",
        "            f.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9V1d-QcQC7D",
        "outputId": "555c7d9a-5aea-4235-c5fd-70ce4236978f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.89)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmdJh-m5QaeY",
        "outputId": "29ca2aa3-2a48-4b24-c966-99e671c29248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available: False\n",
            "GPU Name: No GPU found\n",
            "12.4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "HB9yckyZjddn"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "RCKV2y9SYq8H"
      },
      "outputs": [],
      "source": [
        "data_yaml=\"/content/extracted_files/coco2017_subset/dataset.yaml\"\n",
        "\n",
        "epochs=1\n",
        "img_size=640\n",
        "batch_size=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu7k6t_bjolf",
        "outputId": "db6e739d-e5b7-48b0-fff5-4ee9bae1a48b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting YOLO training...\n",
            "Ultralytics 8.3.89 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/extracted_files/coco2017_subset/dataset.yaml, epochs=1, time=None, patience=100, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 13.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/extracted_files/coco2017_subset/train2017... 29315 images, 256 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29571/29571 [01:43<00:00, 285.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/extracted_files/coco2017_subset/train2017.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/extracted_files/coco2017_subset/val2017... 1237 images, 13 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [00:04<00:00, 287.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/extracted_files/coco2017_subset/val2017.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/1         0G      1.278      1.841      1.329         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14786/14786 [7:25:54<00:00,  1.81s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [05:33<00:00,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1250       9236      0.603      0.461      0.499       0.35\n",
            "\n",
            "1 epochs completed in 7.530 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.89 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [04:47<00:00,  1.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1250       9236      0.605      0.461        0.5       0.35\n",
            "                person        670       2607      0.839      0.584      0.716      0.483\n",
            "               bicycle         34         75      0.516      0.293       0.33      0.205\n",
            "                   car        132        457      0.702      0.453       0.54      0.322\n",
            "            motorcycle         36         88      0.759      0.511      0.585      0.385\n",
            "              airplane         23         43      0.811      0.791       0.81      0.558\n",
            "                   bus         43         55      0.807      0.761       0.79      0.667\n",
            "                 train         48         60      0.821      0.767      0.833      0.666\n",
            "                 truck         56         96      0.662      0.327      0.434      0.292\n",
            "                  boat         30        107      0.585      0.251      0.329      0.168\n",
            "         traffic light         53        176       0.57      0.335      0.396      0.213\n",
            "          fire hydrant         24         26      0.808      0.731      0.756      0.584\n",
            "             stop sign         18         19      0.662      0.579      0.685      0.607\n",
            "         parking meter         11         24      0.519      0.417      0.507      0.371\n",
            "                 bench         55         90      0.466      0.256      0.284      0.163\n",
            "                  bird         35        114      0.698      0.283      0.327      0.194\n",
            "                   cat         57         63      0.877      0.681      0.844       0.66\n",
            "                   dog         41         51      0.656      0.745      0.765      0.612\n",
            "                 horse         40        101      0.726      0.772      0.771      0.576\n",
            "                 sheep         15        124      0.699      0.694      0.741      0.465\n",
            "                   cow         25         74      0.559      0.622      0.647      0.471\n",
            "              elephant         15         49      0.789      0.878        0.9      0.693\n",
            "                  bear         13         18      0.697      0.722      0.798      0.668\n",
            "                 zebra         25         72       0.78      0.889       0.92      0.695\n",
            "               giraffe         29         70       0.77      0.743      0.771       0.58\n",
            "              backpack         52         82      0.456      0.174      0.188      0.113\n",
            "              umbrella         35        110      0.536      0.373      0.389      0.233\n",
            "               handbag         81        156      0.393     0.0641      0.103      0.058\n",
            "                   tie         46         76      0.613      0.303      0.394      0.247\n",
            "              suitcase         29         99      0.541      0.453      0.488       0.33\n",
            "               frisbee         16         30      0.518      0.567      0.475      0.346\n",
            "                  skis         32         57      0.602      0.263      0.299      0.163\n",
            "             snowboard         13         17      0.386      0.235       0.31      0.195\n",
            "           sports ball         50         86      0.871      0.472      0.531      0.397\n",
            "                  kite         23        102      0.553      0.431      0.508      0.339\n",
            "          baseball bat         22         30      0.538        0.4      0.386      0.221\n",
            "        baseball glove         20         24      0.508        0.5        0.5      0.238\n",
            "            skateboard         27         40      0.751      0.526      0.623      0.421\n",
            "             surfboard         43         92      0.648      0.402      0.439       0.28\n",
            "         tennis racket         45         66      0.654      0.485        0.6      0.343\n",
            "                bottle         99        227      0.519      0.313      0.348      0.239\n",
            "            wine glass         29         86      0.718      0.296      0.396      0.278\n",
            "                   cup        106        270      0.588      0.385       0.43      0.282\n",
            "                  fork         37         53      0.685      0.321      0.365       0.26\n",
            "                 knife         44         99      0.303      0.106      0.107     0.0668\n",
            "                 spoon         45         77      0.421     0.0663      0.144     0.0805\n",
            "                  bowl         83        185      0.697      0.335      0.461      0.331\n",
            "                banana         22         69      0.454      0.246      0.289      0.163\n",
            "                 apple         22         59       0.61      0.203      0.243      0.175\n",
            "              sandwich         24         49      0.749      0.243      0.343      0.211\n",
            "                orange         17         41      0.329      0.537      0.365      0.264\n",
            "              broccoli         14         90      0.493      0.311      0.321       0.16\n",
            "                carrot         15         63      0.334      0.246      0.256      0.169\n",
            "               hot dog          9         24      0.575      0.583      0.554      0.408\n",
            "                 pizza         29         47      0.675      0.708      0.759      0.617\n",
            "                 donut         18        112       0.42      0.616       0.46      0.343\n",
            "                  cake         33         79      0.676      0.468      0.553      0.392\n",
            "                 chair        154        437      0.546      0.327      0.374      0.226\n",
            "                 couch         45         70      0.645      0.457      0.486      0.308\n",
            "          potted plant         38         83      0.694      0.337      0.408      0.248\n",
            "                   bed         38         39      0.718      0.692       0.73      0.569\n",
            "          dining table        116        180      0.491      0.413       0.39      0.284\n",
            "                toilet         40         48      0.605      0.638      0.639      0.505\n",
            "                    tv         55         77      0.573      0.714      0.703      0.522\n",
            "                laptop         31         32      0.437      0.719      0.696      0.552\n",
            "                 mouse         20         21      0.474      0.762      0.794      0.632\n",
            "                remote         32         64      0.385      0.203        0.2       0.11\n",
            "              keyboard         21         28      0.537      0.857      0.783      0.597\n",
            "            cell phone         47         55      0.509      0.309      0.359      0.251\n",
            "             microwave         16         17      0.524      0.765      0.646      0.443\n",
            "                  oven         32         40      0.531       0.45      0.531      0.368\n",
            "               toaster          4          5       0.64        0.2       0.56      0.321\n",
            "                  sink         55         73       0.55      0.493      0.547      0.378\n",
            "          refrigerator         34         47      0.684      0.596      0.661       0.49\n",
            "                  book         63        329       0.38     0.0699      0.134     0.0587\n",
            "                 clock         56         66      0.617      0.621      0.596      0.399\n",
            "                  vase         39         76      0.847      0.421      0.555      0.407\n",
            "              scissors         12         17      0.351      0.235      0.166     0.0842\n",
            "            teddy bear         28         59      0.538      0.576      0.574      0.363\n",
            "            hair drier          2          2          1          0          0          0\n",
            "            toothbrush          9         15      0.499      0.267      0.331      0.195\n",
            "Speed: 4.9ms preprocess, 207.9ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Training completed.\n"
          ]
        }
      ],
      "source": [
        "#training\n",
        "print(\"Starting YOLO training...\")\n",
        "results=model.train(data=data_yaml,epochs=epochs,imgsz=img_size,batch=batch_size,device='cpu')\n",
        "print(\"Training completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jilrFOkgN9U2"
      },
      "outputs": [],
      "source": [
        "model.save('best_yolo.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "utEgeP5IOSgf",
        "outputId": "52fc711b-221f-45fa-e42d-7e2af2fca661"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_3da838f6-8e9d-4183-a6e9-848d749b8ce0\", \"best_yolo.pt\", 5534714)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('best_yolo.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "resources": {
            "http://localhost:8080/output_video.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "zNFviWWZir2c",
        "outputId": "ea65ac2a-0bf3-457a-9344-463f53aaf052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 1 traffic light, 186.7ms\n",
            "Speed: 6.9ms preprocess, 186.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 190.0ms\n",
            "Speed: 5.3ms preprocess, 190.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 202.0ms\n",
            "Speed: 5.4ms preprocess, 202.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 bus, 167.1ms\n",
            "Speed: 4.9ms preprocess, 167.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 1 traffic light, 169.0ms\n",
            "Speed: 9.6ms preprocess, 169.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 bus, 1 traffic light, 162.1ms\n",
            "Speed: 5.4ms preprocess, 162.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 1 traffic light, 172.6ms\n",
            "Speed: 4.9ms preprocess, 172.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 1 traffic light, 196.8ms\n",
            "Speed: 6.7ms preprocess, 196.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 1 traffic light, 159.6ms\n",
            "Speed: 5.1ms preprocess, 159.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 traffic light, 164.7ms\n",
            "Speed: 4.2ms preprocess, 164.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 traffic light, 176.3ms\n",
            "Speed: 7.4ms preprocess, 176.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 1 traffic light, 180.5ms\n",
            "Speed: 7.0ms preprocess, 180.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 traffic light, 1 backpack, 186.3ms\n",
            "Speed: 11.5ms preprocess, 186.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 traffic light, 173.6ms\n",
            "Speed: 8.4ms preprocess, 173.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 150.8ms\n",
            "Speed: 5.6ms preprocess, 150.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 159.5ms\n",
            "Speed: 5.1ms preprocess, 159.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 240.4ms\n",
            "Speed: 5.8ms preprocess, 240.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 236.4ms\n",
            "Speed: 5.6ms preprocess, 236.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 232.8ms\n",
            "Speed: 8.9ms preprocess, 232.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 227.1ms\n",
            "Speed: 5.1ms preprocess, 227.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 240.1ms\n",
            "Speed: 5.9ms preprocess, 240.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 231.5ms\n",
            "Speed: 6.0ms preprocess, 231.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 252.1ms\n",
            "Speed: 6.5ms preprocess, 252.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 230.0ms\n",
            "Speed: 6.1ms preprocess, 230.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 244.1ms\n",
            "Speed: 5.2ms preprocess, 244.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 248.7ms\n",
            "Speed: 5.2ms preprocess, 248.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 251.3ms\n",
            "Speed: 5.1ms preprocess, 251.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 235.1ms\n",
            "Speed: 7.8ms preprocess, 235.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 217.6ms\n",
            "Speed: 5.4ms preprocess, 217.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 151.9ms\n",
            "Speed: 5.5ms preprocess, 151.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 397.9ms\n",
            "Speed: 5.2ms preprocess, 397.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 317.6ms\n",
            "Speed: 15.4ms preprocess, 317.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 195.0ms\n",
            "Speed: 5.3ms preprocess, 195.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 293.1ms\n",
            "Speed: 6.0ms preprocess, 293.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 474.8ms\n",
            "Speed: 5.3ms preprocess, 474.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 158.3ms\n",
            "Speed: 6.3ms preprocess, 158.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 224.1ms\n",
            "Speed: 4.8ms preprocess, 224.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 262.1ms\n",
            "Speed: 6.3ms preprocess, 262.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 173.5ms\n",
            "Speed: 5.5ms preprocess, 173.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 backpack, 193.1ms\n",
            "Speed: 6.3ms preprocess, 193.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 154.8ms\n",
            "Speed: 5.0ms preprocess, 154.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 157.6ms\n",
            "Speed: 4.8ms preprocess, 157.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 235.0ms\n",
            "Speed: 4.7ms preprocess, 235.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 275.0ms\n",
            "Speed: 14.6ms preprocess, 275.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 211.2ms\n",
            "Speed: 11.7ms preprocess, 211.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 220.0ms\n",
            "Speed: 11.7ms preprocess, 220.0ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 205.6ms\n",
            "Speed: 6.8ms preprocess, 205.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 237.8ms\n",
            "Speed: 6.8ms preprocess, 237.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 319.7ms\n",
            "Speed: 7.3ms preprocess, 319.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 273.9ms\n",
            "Speed: 7.2ms preprocess, 273.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 182.4ms\n",
            "Speed: 6.0ms preprocess, 182.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 174.1ms\n",
            "Speed: 5.0ms preprocess, 174.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 147.9ms\n",
            "Speed: 5.0ms preprocess, 147.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 187.1ms\n",
            "Speed: 5.1ms preprocess, 187.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 179.7ms\n",
            "Speed: 7.1ms preprocess, 179.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 166.5ms\n",
            "Speed: 8.5ms preprocess, 166.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 168.0ms\n",
            "Speed: 4.6ms preprocess, 168.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 156.2ms\n",
            "Speed: 5.1ms preprocess, 156.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 1 bus, 159.8ms\n",
            "Speed: 5.2ms preprocess, 159.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 151.5ms\n",
            "Speed: 5.7ms preprocess, 151.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 158.6ms\n",
            "Speed: 4.6ms preprocess, 158.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 160.2ms\n",
            "Speed: 5.6ms preprocess, 160.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 174.8ms\n",
            "Speed: 5.8ms preprocess, 174.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 159.1ms\n",
            "Speed: 4.9ms preprocess, 159.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 153.9ms\n",
            "Speed: 4.9ms preprocess, 153.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 158.1ms\n",
            "Speed: 4.9ms preprocess, 158.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 1 bus, 164.0ms\n",
            "Speed: 4.6ms preprocess, 164.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 191.8ms\n",
            "Speed: 5.9ms preprocess, 191.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 157.6ms\n",
            "Speed: 6.1ms preprocess, 157.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 3 motorcycles, 1 bus, 163.3ms\n",
            "Speed: 5.2ms preprocess, 163.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 motorcycle, 155.5ms\n",
            "Speed: 4.9ms preprocess, 155.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 motorcycles, 1 bus, 160.8ms\n",
            "Speed: 5.0ms preprocess, 160.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 motorcycles, 167.6ms\n",
            "Speed: 5.2ms preprocess, 167.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 motorcycles, 254.7ms\n",
            "Speed: 6.1ms preprocess, 254.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 motorcycles, 229.3ms\n",
            "Speed: 2.6ms preprocess, 229.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 245.6ms\n",
            "Speed: 5.9ms preprocess, 245.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 2 motorcycles, 270.5ms\n",
            "Speed: 5.1ms preprocess, 270.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 242.7ms\n",
            "Speed: 5.9ms preprocess, 242.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 223.6ms\n",
            "Speed: 7.8ms preprocess, 223.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 2 motorcycles, 226.1ms\n",
            "Speed: 5.6ms preprocess, 226.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 motorcycle, 263.5ms\n",
            "Speed: 5.0ms preprocess, 263.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 2 motorcycles, 238.9ms\n",
            "Speed: 5.2ms preprocess, 238.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 3 motorcycles, 235.1ms\n",
            "Speed: 5.1ms preprocess, 235.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 240.3ms\n",
            "Speed: 2.5ms preprocess, 240.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 4 motorcycles, 260.8ms\n",
            "Speed: 5.5ms preprocess, 260.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 1 bus, 158.2ms\n",
            "Speed: 5.3ms preprocess, 158.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 3 motorcycles, 164.0ms\n",
            "Speed: 5.5ms preprocess, 164.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 2 motorcycles, 167.2ms\n",
            "Speed: 5.0ms preprocess, 167.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 1 bus, 154.5ms\n",
            "Speed: 5.8ms preprocess, 154.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 175.8ms\n",
            "Speed: 4.7ms preprocess, 175.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 184.1ms\n",
            "Speed: 6.9ms preprocess, 184.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 2 motorcycles, 156.7ms\n",
            "Speed: 5.3ms preprocess, 156.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 154.2ms\n",
            "Speed: 5.4ms preprocess, 154.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 160.4ms\n",
            "Speed: 4.1ms preprocess, 160.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 1 bus, 166.2ms\n",
            "Speed: 5.0ms preprocess, 166.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 2 motorcycles, 1 bus, 205.8ms\n",
            "Speed: 5.6ms preprocess, 205.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 2 motorcycles, 1 bus, 149.9ms\n",
            "Speed: 4.9ms preprocess, 149.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 motorcycle, 1 bus, 156.5ms\n",
            "Speed: 5.3ms preprocess, 156.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 1 bus, 152.8ms\n",
            "Speed: 5.1ms preprocess, 152.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 bus, 163.0ms\n",
            "Speed: 6.3ms preprocess, 163.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 2 motorcycles, 192.0ms\n",
            "Speed: 4.7ms preprocess, 192.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 motorcycle, 1 bus, 169.3ms\n",
            "Speed: 5.5ms preprocess, 169.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 1 bus, 158.9ms\n",
            "Speed: 4.3ms preprocess, 158.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 2 motorcycles, 160.9ms\n",
            "Speed: 5.4ms preprocess, 160.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 2 motorcycles, 1 bus, 151.4ms\n",
            "Speed: 4.9ms preprocess, 151.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 motorcycle, 1 bus, 165.1ms\n",
            "Speed: 5.0ms preprocess, 165.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 motorcycle, 1 bus, 173.7ms\n",
            "Speed: 4.5ms preprocess, 173.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 165.0ms\n",
            "Speed: 4.8ms preprocess, 165.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 1 bus, 145.5ms\n",
            "Speed: 4.2ms preprocess, 145.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 motorcycle, 161.9ms\n",
            "Speed: 5.0ms preprocess, 161.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 2 motorcycles, 155.5ms\n",
            "Speed: 5.4ms preprocess, 155.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 2 motorcycles, 191.5ms\n",
            "Speed: 5.5ms preprocess, 191.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 motorcycles, 149.3ms\n",
            "Speed: 4.8ms preprocess, 149.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 2 motorcycles, 154.6ms\n",
            "Speed: 5.7ms preprocess, 154.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 2 motorcycles, 149.8ms\n",
            "Speed: 5.3ms preprocess, 149.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 1 bus, 156.1ms\n",
            "Speed: 4.3ms preprocess, 156.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 147.5ms\n",
            "Speed: 5.0ms preprocess, 147.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 1 bus, 183.8ms\n",
            "Speed: 7.2ms preprocess, 183.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 171.3ms\n",
            "Speed: 5.1ms preprocess, 171.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 1 bus, 153.8ms\n",
            "Speed: 2.5ms preprocess, 153.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 1 bus, 154.2ms\n",
            "Speed: 4.9ms preprocess, 154.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 153.5ms\n",
            "Speed: 5.6ms preprocess, 153.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 171.5ms\n",
            "Speed: 6.2ms preprocess, 171.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 1 bus, 168.2ms\n",
            "Speed: 5.8ms preprocess, 168.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 181.8ms\n",
            "Speed: 5.4ms preprocess, 181.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 150.6ms\n",
            "Speed: 6.5ms preprocess, 150.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 180.2ms\n",
            "Speed: 5.0ms preprocess, 180.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 171.3ms\n",
            "Speed: 2.6ms preprocess, 171.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 194.4ms\n",
            "Speed: 7.5ms preprocess, 194.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 162.6ms\n",
            "Speed: 5.6ms preprocess, 162.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 175.3ms\n",
            "Speed: 10.1ms preprocess, 175.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 bus, 151.9ms\n",
            "Speed: 5.2ms preprocess, 151.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 154.1ms\n",
            "Speed: 5.7ms preprocess, 154.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 193.0ms\n",
            "Speed: 7.8ms preprocess, 193.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 bus, 165.8ms\n",
            "Speed: 4.9ms preprocess, 165.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 168.9ms\n",
            "Speed: 6.6ms preprocess, 168.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 155.5ms\n",
            "Speed: 5.3ms preprocess, 155.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 158.5ms\n",
            "Speed: 6.2ms preprocess, 158.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 164.0ms\n",
            "Speed: 2.9ms preprocess, 164.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 242.9ms\n",
            "Speed: 5.0ms preprocess, 242.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 254.5ms\n",
            "Speed: 5.3ms preprocess, 254.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 262.9ms\n",
            "Speed: 6.9ms preprocess, 262.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 270.8ms\n",
            "Speed: 5.0ms preprocess, 270.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 240.7ms\n",
            "Speed: 7.9ms preprocess, 240.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 238.1ms\n",
            "Speed: 5.3ms preprocess, 238.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 254.9ms\n",
            "Speed: 5.0ms preprocess, 254.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 270.6ms\n",
            "Speed: 10.4ms preprocess, 270.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 253.1ms\n",
            "Speed: 5.6ms preprocess, 253.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 273.2ms\n",
            "Speed: 5.3ms preprocess, 273.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 291.3ms\n",
            "Speed: 6.7ms preprocess, 291.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 190.9ms\n",
            "Speed: 9.8ms preprocess, 190.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 1 bus, 149.5ms\n",
            "Speed: 2.4ms preprocess, 149.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 165.1ms\n",
            "Speed: 6.0ms preprocess, 165.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 1 bus, 153.4ms\n",
            "Speed: 5.0ms preprocess, 153.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 175.0ms\n",
            "Speed: 4.8ms preprocess, 175.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 1 bus, 152.7ms\n",
            "Speed: 5.0ms preprocess, 152.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 motorcycle, 1 bus, 149.8ms\n",
            "Speed: 5.3ms preprocess, 149.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 150.6ms\n",
            "Speed: 5.0ms preprocess, 150.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 193.7ms\n",
            "Speed: 5.9ms preprocess, 193.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 218.5ms\n",
            "Speed: 8.4ms preprocess, 218.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 motorcycle, 1 bus, 171.0ms\n",
            "Speed: 8.3ms preprocess, 171.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 motorcycle, 1 bus, 153.5ms\n",
            "Speed: 5.0ms preprocess, 153.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 motorcycle, 1 bus, 146.8ms\n",
            "Speed: 5.9ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 motorcycle, 1 bus, 150.9ms\n",
            "Speed: 5.3ms preprocess, 150.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 motorcycle, 165.5ms\n",
            "Speed: 5.0ms preprocess, 165.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 1 bus, 169.0ms\n",
            "Speed: 5.7ms preprocess, 169.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 motorcycle, 1 bus, 157.2ms\n",
            "Speed: 5.5ms preprocess, 157.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 motorcycle, 1 bus, 160.2ms\n",
            "Speed: 5.3ms preprocess, 160.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 149.1ms\n",
            "Speed: 5.5ms preprocess, 149.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 bus, 163.8ms\n",
            "Speed: 5.1ms preprocess, 163.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 168.8ms\n",
            "Speed: 4.9ms preprocess, 168.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 180.3ms\n",
            "Speed: 5.7ms preprocess, 180.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 cars, 1 bus, 165.9ms\n",
            "Speed: 4.8ms preprocess, 165.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 motorcycle, 146.7ms\n",
            "Speed: 5.6ms preprocess, 146.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 147.5ms\n",
            "Speed: 4.8ms preprocess, 147.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 178.3ms\n",
            "Speed: 5.0ms preprocess, 178.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 174.2ms\n",
            "Speed: 4.8ms preprocess, 174.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 157.2ms\n",
            "Speed: 4.7ms preprocess, 157.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 150.0ms\n",
            "Speed: 5.9ms preprocess, 150.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 153.5ms\n",
            "Speed: 4.1ms preprocess, 153.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 144.6ms\n",
            "Speed: 4.6ms preprocess, 144.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 185.1ms\n",
            "Speed: 6.7ms preprocess, 185.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 168.3ms\n",
            "Speed: 5.4ms preprocess, 168.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 169.3ms\n",
            "Speed: 5.1ms preprocess, 169.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 174.5ms\n",
            "Speed: 3.3ms preprocess, 174.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 187.4ms\n",
            "Speed: 5.4ms preprocess, 187.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 179.6ms\n",
            "Speed: 6.1ms preprocess, 179.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 176.5ms\n",
            "Speed: 6.8ms preprocess, 176.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 154.4ms\n",
            "Speed: 5.0ms preprocess, 154.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 151.7ms\n",
            "Speed: 8.0ms preprocess, 151.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 196.6ms\n",
            "Speed: 7.4ms preprocess, 196.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 201.3ms\n",
            "Speed: 7.1ms preprocess, 201.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 156.2ms\n",
            "Speed: 8.4ms preprocess, 156.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 152.4ms\n",
            "Speed: 7.8ms preprocess, 152.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 149.0ms\n",
            "Speed: 6.1ms preprocess, 149.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 160.5ms\n",
            "Speed: 5.7ms preprocess, 160.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 176.1ms\n",
            "Speed: 6.7ms preprocess, 176.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 318.4ms\n",
            "Speed: 7.9ms preprocess, 318.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 217.3ms\n",
            "Speed: 6.5ms preprocess, 217.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 bus, 202.3ms\n",
            "Speed: 5.3ms preprocess, 202.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 bus, 232.0ms\n",
            "Speed: 6.3ms preprocess, 232.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 1 truck, 206.3ms\n",
            "Speed: 9.3ms preprocess, 206.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 1 truck, 261.4ms\n",
            "Speed: 2.5ms preprocess, 261.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 308.1ms\n",
            "Speed: 5.5ms preprocess, 308.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 1 truck, 285.2ms\n",
            "Speed: 8.5ms preprocess, 285.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 bus, 1 truck, 286.5ms\n",
            "Speed: 6.1ms preprocess, 286.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 1 truck, 230.1ms\n",
            "Speed: 5.3ms preprocess, 230.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 291.7ms\n",
            "Speed: 2.8ms preprocess, 291.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 274.9ms\n",
            "Speed: 10.3ms preprocess, 274.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 243.4ms\n",
            "Speed: 5.7ms preprocess, 243.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 232.1ms\n",
            "Speed: 5.6ms preprocess, 232.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 256.2ms\n",
            "Speed: 5.2ms preprocess, 256.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 251.0ms\n",
            "Speed: 5.8ms preprocess, 251.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 bus, 246.3ms\n",
            "Speed: 8.0ms preprocess, 246.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 186.7ms\n",
            "Speed: 6.0ms preprocess, 186.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 186.5ms\n",
            "Speed: 4.5ms preprocess, 186.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 174.0ms\n",
            "Speed: 2.9ms preprocess, 174.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 cars, 1 bus, 176.0ms\n",
            "Speed: 6.2ms preprocess, 176.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 165.6ms\n",
            "Speed: 3.1ms preprocess, 165.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 174.2ms\n",
            "Speed: 6.4ms preprocess, 174.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 185.9ms\n",
            "Speed: 6.8ms preprocess, 185.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 173.0ms\n",
            "Speed: 8.4ms preprocess, 173.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 158.9ms\n",
            "Speed: 4.4ms preprocess, 158.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 cars, 1 bus, 163.4ms\n",
            "Speed: 5.2ms preprocess, 163.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 155.9ms\n",
            "Speed: 5.4ms preprocess, 155.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 155.7ms\n",
            "Speed: 4.3ms preprocess, 155.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 180.1ms\n",
            "Speed: 4.1ms preprocess, 180.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 169.4ms\n",
            "Speed: 5.0ms preprocess, 169.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 173.8ms\n",
            "Speed: 5.6ms preprocess, 173.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 155.6ms\n",
            "Speed: 3.9ms preprocess, 155.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 153.3ms\n",
            "Speed: 5.1ms preprocess, 153.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 162.8ms\n",
            "Speed: 2.8ms preprocess, 162.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 161.3ms\n",
            "Speed: 5.2ms preprocess, 161.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 cars, 1 bus, 153.6ms\n",
            "Speed: 5.4ms preprocess, 153.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 157.8ms\n",
            "Speed: 5.3ms preprocess, 157.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 152.0ms\n",
            "Speed: 3.3ms preprocess, 152.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 157.1ms\n",
            "Speed: 5.7ms preprocess, 157.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 184.1ms\n",
            "Speed: 6.6ms preprocess, 184.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 158.7ms\n",
            "Speed: 4.5ms preprocess, 158.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 160.8ms\n",
            "Speed: 5.2ms preprocess, 160.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 166.5ms\n",
            "Speed: 4.5ms preprocess, 166.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 153.7ms\n",
            "Speed: 5.8ms preprocess, 153.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 169.4ms\n",
            "Speed: 6.3ms preprocess, 169.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 171.7ms\n",
            "Speed: 4.2ms preprocess, 171.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 152.8ms\n",
            "Speed: 5.1ms preprocess, 152.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 153.3ms\n",
            "Speed: 5.0ms preprocess, 153.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 169.6ms\n",
            "Speed: 5.0ms preprocess, 169.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 157.3ms\n",
            "Speed: 5.9ms preprocess, 157.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 176.2ms\n",
            "Speed: 2.6ms preprocess, 176.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 cars, 1 bus, 156.2ms\n",
            "Speed: 7.6ms preprocess, 156.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 165.6ms\n",
            "Speed: 5.4ms preprocess, 165.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 170.1ms\n",
            "Speed: 5.6ms preprocess, 170.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 161.5ms\n",
            "Speed: 5.3ms preprocess, 161.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 164.2ms\n",
            "Speed: 5.3ms preprocess, 164.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 169.4ms\n",
            "Speed: 5.0ms preprocess, 169.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 155.0ms\n",
            "Speed: 5.4ms preprocess, 155.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 153.0ms\n",
            "Speed: 2.8ms preprocess, 153.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 172.4ms\n",
            "Speed: 5.0ms preprocess, 172.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 153.1ms\n",
            "Speed: 6.6ms preprocess, 153.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 187.3ms\n",
            "Speed: 5.3ms preprocess, 187.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 161.9ms\n",
            "Speed: 5.4ms preprocess, 161.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 156.4ms\n",
            "Speed: 5.1ms preprocess, 156.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 155.2ms\n",
            "Speed: 5.2ms preprocess, 155.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 166.2ms\n",
            "Speed: 5.7ms preprocess, 166.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 150.4ms\n",
            "Speed: 5.8ms preprocess, 150.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 173.9ms\n",
            "Speed: 5.3ms preprocess, 173.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 157.0ms\n",
            "Speed: 3.7ms preprocess, 157.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 156.5ms\n",
            "Speed: 5.5ms preprocess, 156.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 147.4ms\n",
            "Speed: 4.8ms preprocess, 147.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 231.6ms\n",
            "Speed: 4.9ms preprocess, 231.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 267.3ms\n",
            "Speed: 5.2ms preprocess, 267.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 244.9ms\n",
            "Speed: 6.3ms preprocess, 244.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 237.7ms\n",
            "Speed: 6.3ms preprocess, 237.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 300.0ms\n",
            "Speed: 9.0ms preprocess, 300.0ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 893.3ms\n",
            "Speed: 8.3ms preprocess, 893.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 233.0ms\n",
            "Speed: 5.2ms preprocess, 233.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 235.4ms\n",
            "Speed: 6.0ms preprocess, 235.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 228.7ms\n",
            "Speed: 5.0ms preprocess, 228.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 213.2ms\n",
            "Speed: 5.3ms preprocess, 213.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 187.9ms\n",
            "Speed: 7.9ms preprocess, 187.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 183.1ms\n",
            "Speed: 2.6ms preprocess, 183.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 165.1ms\n",
            "Speed: 2.7ms preprocess, 165.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 bus, 169.4ms\n",
            "Speed: 2.5ms preprocess, 169.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 178.2ms\n",
            "Speed: 7.0ms preprocess, 178.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 209.1ms\n",
            "Speed: 5.8ms preprocess, 209.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 170.1ms\n",
            "Speed: 5.3ms preprocess, 170.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 160.0ms\n",
            "Speed: 6.7ms preprocess, 160.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 154.3ms\n",
            "Speed: 5.7ms preprocess, 154.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 151.7ms\n",
            "Speed: 5.6ms preprocess, 151.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 215.3ms\n",
            "Speed: 5.9ms preprocess, 215.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 157.4ms\n",
            "Speed: 5.5ms preprocess, 157.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 163.6ms\n",
            "Speed: 5.7ms preprocess, 163.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 149.8ms\n",
            "Speed: 5.1ms preprocess, 149.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 151.9ms\n",
            "Speed: 5.6ms preprocess, 151.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 174.2ms\n",
            "Speed: 6.1ms preprocess, 174.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 182.7ms\n",
            "Speed: 5.6ms preprocess, 182.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 160.8ms\n",
            "Speed: 6.0ms preprocess, 160.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 148.7ms\n",
            "Speed: 5.0ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 cars, 1 bus, 161.2ms\n",
            "Speed: 4.4ms preprocess, 161.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 cars, 1 bus, 150.7ms\n",
            "Speed: 5.0ms preprocess, 150.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 cars, 1 bus, 173.9ms\n",
            "Speed: 6.0ms preprocess, 173.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Moviepy - Building video output_video.mp4.\n",
            "Moviepy - Writing video output_video.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output_video.mp4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"360\" controls>\n",
              "  <source src=\"output_video.mp4\" type=\"video/mp4\">\n",
              "Your browser does not support the video tag.\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install moviepy\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "\n",
        "# Load YOLO model\n",
        "model_path = r\"/content/extracted_files/coco2017_subset/best_yolo.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Open video file\n",
        "video_path = r\"/content/road_trafifc.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Video file not found or cannot be opened!\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Store processed frames\n",
        "frames = []\n",
        "\n",
        "# Loop through video frames\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Exit when video ends\n",
        "\n",
        "    # Run YOLO on the current frame\n",
        "    results = model.predict(frame, conf=0.5)\n",
        "\n",
        "    # Extract the frame with detected objects\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Append the annotated frame to the list\n",
        "    frames.append(annotated_frame)\n",
        "\n",
        "# Release video capture\n",
        "cap.release()\n",
        "\n",
        "# Create video clip from frames\n",
        "clip = ImageSequenceClip(frames, fps=fps)\n",
        "\n",
        "# Save the video clip (optional)\n",
        "clip.write_videofile(\"output_video.mp4\", codec=\"libx264\", fps=fps)\n",
        "\n",
        "# Display the video in Colab (using HTML5 video)\n",
        "from IPython.display import HTML\n",
        "HTML(\"\"\"\n",
        "<video width=\"{}\" height=\"{}\" controls>\n",
        "  <source src=\"output_video.mp4\" type=\"video/mp4\">\n",
        "Your browser does not support the video tag.\n",
        "</video>\n",
        "\"\"\".format(width, height))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
